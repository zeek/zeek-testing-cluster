# Basic helpers sourced by some of the tests.

# A subset of the tests uses "set -e", so we need to ensure that helpers that
# may naturally hit transient failures don't abort a test. We temporarily set +e
# in such functions.

# Exits with error and error message.
fail() {
    local msg="$1"
    echo "failure: $msg"
    exit 1
}

# Runs a given command, saving stdout and stderr to separate, named files, and
# validates exit code. Exits with error if validation fails.
run() {
    local cmd="$1"
    local ret="$2"
    local name="$3"

    _impl() {
        # Save outputs if caller requested it
        if [ -n "$name" ]; then
            { eval "$cmd"; } >output.$name 2>stderr.$name
        else
            eval "$cmd"
        fi
        [ $? -eq $ret ] || fail "[$name] '$cmd' did not exit with $ret"
    }

    local errexit=false
    [ -o errexit ] && errexit=true
    set +e
    _impl
    [ $errexit == true ] && set -e

    return 0
}

# Try a given command repeatedly for up to the configurable number of seconds
# until it succeeds. The default is to try twice a second for 5 seconds. Use
# -d/-i to pass custom delays and intervals -- these must come as first
# arguments. Returns with success if the command eventually succeeded, and
# failure if time ran out.
try_until() {
    local delay_secs=5
    local delay_ival=0.5

    while [ "$1" != "" ]; do
        case "$1" in
            "-d"|"--delay-secs")
                delay_secs="$2"
                shift 2
                ;;
            "-i"|"--interval-secs")
                delay_ival="$2"
                shift 2
                ;;
            *)
                break
                ;;
        esac
    done

    local reps="$(python3 -c "print($delay_secs / $delay_ival)")"

    for i in $(seq $reps); do
        "$@" && return 0
        sleep "$delay_ival"
    done

    return 1
}

# Checks current instance state via "zeek-client get-instances" until it sees
# the requested number of connected agents, or 10 seconds have passed. Exits
# with 0 once the instances are seen, 1 when the timeout hits or other problems
# arise.
wait_for_instances() {
    local num_instances="$1"

    _impl() {
        for i in $(seq 10); do
            local cur_instances=$(zeek_client get-instances | jq 'keys|length')
            if [ -n "$cur_instances" ] && [ $cur_instances -eq $num_instances ]; then
                return 0
            fi
            sleep 1
        done

        return 1
    }

    local errexit=false
    [ -o errexit ] && errexit=true
    set +e
    _impl
    local ret=$?
    [ $errexit == true ] && set -e

    return $ret
}

# Checks current cluster node state via "zeek-client get-nodes" until nodes get
# reported and all nodes are in running state, or 10 seconds have passed. Exits
# with 0 once all nodes are running, 1 when the timeout is hit or other problems
# arise. Takes one optional argument: the number of nodes to expect.
wait_for_all_nodes_running() {
    local nodes=${1:-0}

    _impl() {
        for i in $(seq 10); do
            # Retrieve node status, and extract run states from it.
            # Count how often that is "RUNNING" vs something else.
            zeek_client get-nodes \
                | jq -r '.results[][].state' \
                | awk "BEGIN  { r = 0; o = 0 }
                      /RUNNING/  { r += 1 }
                      !/RUNNING/ { o += 1 }
                      END        { if ( $nodes == 0 ) { printf \"waiting for all nodes running: running %s, other %s\n\", r, o; }
                                   else { printf \"waiting for $nodes nodes: running %s, other %s\n\", r, o; }
                                   if ( r > 0 && o == 0 && ( $nodes == 0 || $nodes == r ) ) { exit 0 };
                                   exit 1 }"

            [ $? -eq 0 ] && return 0
            sleep 1
        done

        return 1
    }

    local errexit=false
    [ -o errexit ] && errexit=true
    set +e
    _impl
    local ret=$?
    [ $errexit == true ] && set -e
    return $ret
}

assert_get_nodes_pids() {
    local out1="$1"
    local out2="$2"
    local op="$3"
    local node="$4"

    # The jq filter combines all of the individual nodes objects into one
    # object, from which we then query the requested one. This ensures we
    # get one result, not additional null ones for multi-instance configs.
    local pid1=$(echo $out1 | jq "[.results|.[]] | add | .\"$node\".pid" || true)
    local pid2=$(echo $out2 | jq "[.results|.[]] | add | .\"$node\".pid" || true)

    [ -z "$pid1" ] && fail "PID for $node unavailable in old input"
    [ -z "$pid2" ] && fail "PID for $node unavailable in new input"

    if [ $op == equal ]; then
        [ "$pid1" -eq "$pid2" ] || fail "PIDs for $node differ: $pid1/$pid2"
    else
        [ "$pid1" -ne "$pid2" ] || fail "PIDs for $node match: $pid1/$pid2"
    fi
}
